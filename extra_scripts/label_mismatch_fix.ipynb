{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb96066",
   "metadata": {},
   "source": [
    "Some label masks have one class missing. So need to check and figure out how to fix it.\n",
    "Need the shape of `target` and `predicted` mask to be same for loss calcualtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b975948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO version: 0.18.76\n",
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "\n",
    "print('TorchIO version:', tio.__version__)\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c347a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/media/trojan/trojan/3D-CT-Artery-Segmentation/data_splitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9552fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 612 training subjects\n"
     ]
    }
   ],
   "source": [
    "images_dir = os.path.join(dataset_dir, 'train/volumes')\n",
    "labels_dir = os.path.join(dataset_dir, 'train/masks')\n",
    "image_paths = sorted(glob.glob(images_dir + '/' + '*.nii.gz'))\n",
    "label_paths = sorted(glob.glob(labels_dir + '/' + '*.nii.gz'))\n",
    "assert len(image_paths) == len(label_paths)\n",
    "\n",
    "training_subjects = []\n",
    "for (image_path, label_path) in zip(image_paths, label_paths):\n",
    "    subject = tio.Subject(\n",
    "        image=tio.ScalarImage(image_path),\n",
    "        label=tio.LabelMap(label_path),\n",
    "    )\n",
    "    training_subjects.append(subject)\n",
    "training_dataset = tio.SubjectsDataset(training_subjects)\n",
    "print('Dataset size:', len(training_dataset), 'training subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99abaa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 204 validation subjects\n"
     ]
    }
   ],
   "source": [
    "validation_images_dir = os.path.join(dataset_dir, 'val/volumes')\n",
    "validation_labels_dir = os.path.join(dataset_dir, 'val/masks')\n",
    "validation_image_paths = sorted(glob.glob(validation_images_dir + '/' + '*.nii.gz'))\n",
    "validation_label_paths = sorted(glob.glob(validation_labels_dir + '/' + '*.nii.gz'))\n",
    "assert len(validation_image_paths) == len(validation_label_paths)\n",
    "\n",
    "validation_subjects = []\n",
    "for (image_path, label_path) in zip(validation_image_paths, validation_label_paths):\n",
    "    subject = tio.Subject(\n",
    "        image=tio.ScalarImage(image_path),\n",
    "        label=tio.LabelMap(label_path),\n",
    "    )\n",
    "    validation_subjects.append(subject)\n",
    "validation_dataset = tio.SubjectsDataset(validation_subjects)\n",
    "print('Dataset size:', len(validation_dataset), 'validation subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196e52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_equal = 0\n",
    "# count_diff = 0\n",
    "# for sample in validation_dataset:\n",
    "#     transform = tio.OneHot()\n",
    "#     transformed = transform(sample)\n",
    "#     print(transformed.image.data.shape, transformed.label.data.shape)\n",
    "#     if transformed.label.data.shape[0] == 3:\n",
    "#         print(\"True\")\n",
    "#         count_equal += 1\n",
    "#     else:\n",
    "#         print(\"False\")\n",
    "#         count_diff += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb1191",
   "metadata": {},
   "source": [
    "Check all data. If size is different i.e. label is missing, then print the name of that volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d2e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training data\n",
    "# issue_masks = []\n",
    "\n",
    "# for label_path in label_paths:\n",
    "#     label = tio.LabelMap(label_path)\n",
    "#     unique_labels = np.unique(label.data)\n",
    "    \n",
    "#     # Check label sizes and save the issue masks\n",
    "#     if unique_labels.shape != (3,):\n",
    "#         print(\"Size is not correct.\")\n",
    "#         print(label_path.split(\"/\")[-1])\n",
    "#         issue_masks.append(label_path.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c170f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validation data\n",
    "# val_issue_masks = []\n",
    "\n",
    "# for label_path in validation_label_paths:\n",
    "#     label = tio.LabelMap(label_path)\n",
    "#     unique_labels = np.unique(label.data)\n",
    "    \n",
    "#     # Check label sizes and save the issue masks\n",
    "#     if unique_labels.shape != (3,):\n",
    "#         print(\"Size is not correct.\")\n",
    "#         print(label_path.split(\"/\")[-1])\n",
    "#         val_issue_masks.append(label_path.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235f49c",
   "metadata": {},
   "source": [
    "Patient 2 and 6 have missing labels. Now we have to check which labels are missing for each patient.\n",
    "label_map = {'Background': 0,'temporal_artery': 1,'facial_artery': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9228739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which labels are missing \n",
    "\n",
    "for label_path in glob.glob(validation_labels_dir + '/*.nii.gz'):\n",
    "#     print(mask)\n",
    "#     print(mask.split('/')[-1].split('.')[0].split('_')[0])\n",
    "#     break\n",
    "    split = label_path.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    \n",
    "    if split == '2':\n",
    "        print(f\"*** Patient {split} ***\")\n",
    "        label = tio.LabelMap(label_path)\n",
    "        unique_labels = np.unique(label.data)\n",
    "        print(unique_labels)\n",
    "    \n",
    "    if split == '6':\n",
    "        print(f\"*** Patient {split} ***\")\n",
    "        label = tio.LabelMap(label_path)\n",
    "        unique_labels = np.unique(label.data)\n",
    "        print(unique_labels)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269d034",
   "metadata": {},
   "source": [
    "Patient 2 has a missing label and Patient 6 has an extra label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047b692",
   "metadata": {},
   "source": [
    "# Extra class fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e63ce9",
   "metadata": {},
   "source": [
    "The `extra` label issue is because of separate label for left and right **facial artery**. I can fix it by combining them into one label.\n",
    "However I need to do it before apply `transform.Compose()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f037f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# sample_path = os.path.join(labels_dir, '6.nii.gz')\n",
    "# label = tio.LabelMap(sample_path)\n",
    "# unique_labels = np.unique(label.data)\n",
    "# print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7da2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_337456/4153960674.py:2: DeprecationWarning: Call to deprecated function (or staticmethod) data. (Setting the image data with the property setter is deprecated. Use the set_data() method instead) -- Deprecated since version 0.18.16.\n",
      "  label.data = np.where(label.data > 2, 2, label.data)\n"
     ]
    }
   ],
   "source": [
    "# label.data[label.data==3] = 2\n",
    "# label.data = np.where(label.data > 2, 2, label.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29622b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# unique_labels = np.unique(label.data)\n",
    "# print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35926552",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m subject \u001b[38;5;241m=\u001b[39m tio\u001b[38;5;241m.\u001b[39mSubject(\n\u001b[1;32m     17\u001b[0m     image\u001b[38;5;241m=\u001b[39mtio\u001b[38;5;241m.\u001b[39mScalarImage(image_path),\n\u001b[1;32m     18\u001b[0m     label\u001b[38;5;241m=\u001b[39mtio\u001b[38;5;241m.\u001b[39mLabelMap(label_path)\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#print(subject.label.data.shape)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msubject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#subject.label.data[subject.label.data==3] = 2\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     subject\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(subject\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, subject\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     26\u001b[0m training_subjects_fixed\u001b[38;5;241m.\u001b[39mappend(subject)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/data/image.py:210\u001b[0m, in \u001b[0;36mImage.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124;03m\"\"\"Tensor data. Same as :class:`Image.tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/data/image.py:188\u001b[0m, in \u001b[0;36mImage.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m (DATA, AFFINE):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(item)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/data/image.py:513\u001b[0m, in \u001b[0;36mImage.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    512\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multipath() \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath]\n\u001b[0;32m--> 513\u001b[0m tensor, affine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_and_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m tensors \u001b[38;5;241m=\u001b[39m [tensor]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/data/image.py:539\u001b[0m, in \u001b[0;36mImage.read_and_check\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_check\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: TypePath) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TypeDataAffine:\n\u001b[0;32m--> 539\u001b[0m     tensor, affine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# Make sure the data type is compatible with PyTorch\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_image \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/data/io.py:31\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_image\u001b[39m(path: TypePath) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TypeDataAffine:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_read_sitk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# try with NiBabel\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError loading image with SimpleITK:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTrying NiBabel...\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/data/io.py:66\u001b[0m, in \u001b[0;36m_read_sitk\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     64\u001b[0m     image \u001b[38;5;241m=\u001b[39m _read_dicom(path)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43msitk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReadImage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m data, affine \u001b[38;5;241m=\u001b[39m sitk_to_nib(image, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m data \u001b[38;5;241m=\u001b[39m check_uint_to_int(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/SimpleITK/extra.py:346\u001b[0m, in \u001b[0;36mReadImage\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    344\u001b[0m reader\u001b[38;5;241m.\u001b[39mSetImageIO(imageIO)\n\u001b[1;32m    345\u001b[0m reader\u001b[38;5;241m.\u001b[39mSetOutputPixelType(outputPixelType)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/SimpleITK/SimpleITK.py:8015\u001b[0m, in \u001b[0;36mImageFileReader.Execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mExecute\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   8010\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8011\u001b[0m \u001b[38;5;124;03m    Execute(ImageFileReader self) -> Image\u001b[39;00m\n\u001b[1;32m   8012\u001b[0m \n\u001b[1;32m   8013\u001b[0m \n\u001b[1;32m   8014\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SimpleITK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFileReader_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# images_dir = os.path.join(dataset_dir, 'train/volumes')\n",
    "# labels_dir = os.path.join(dataset_dir, 'train/masks')\n",
    "# image_paths = sorted(glob.glob(images_dir + '/' + '*.nii.gz'))\n",
    "# label_paths = sorted(glob.glob(labels_dir + '/' + '*.nii.gz'))\n",
    "# assert len(image_paths) == len(label_paths)\n",
    "\n",
    "# training_subjects_fixed = []\n",
    "# for (image_path, label_path) in zip(image_paths, label_paths):\n",
    "#     label = tio.LabelMap(label_path)\n",
    "#     unique_labels = np.unique(label.data)\n",
    "    \n",
    "#     if len(unique_labels) > 3: \n",
    "#         print(label_path)\n",
    "#     label.data[label.data==3] = 2\n",
    "    \n",
    "#     subject = tio.Subject(\n",
    "#         image=tio.ScalarImage(image_path),\n",
    "#         label=label\n",
    "#     )\n",
    "        \n",
    "#     training_subjects_fixed.append(subject)\n",
    "\n",
    "# # print('Dataset size:', len(training_subjects_fixed), 'training subjects')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d539beb4",
   "metadata": {},
   "source": [
    "Online is taking really long time. Need to do it offline. Change the values and save the mask again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6037f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all paths\n",
    "\n",
    "issue_file_paths = []\n",
    "\n",
    "for label_path in glob.glob(labels_dir + '/*.nii.gz'):\n",
    "    split = label_path.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    \n",
    "    if split == '6':\n",
    "        issue_file_paths.append(label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ad1e7",
   "metadata": {},
   "source": [
    "## Test on one sample volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b744e2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# for path in issue_file_paths:\n",
    "#     label = tio.LabelMap(sample_path)\n",
    "#     unique_labels = np.unique(label.data)\n",
    "#     print(unique_labels)\n",
    "#     label.data[label.data==3] = 2\n",
    "#     unique_labels = np.unique(label.data)\n",
    "#     print(unique_labels)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40f8c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in issue_file_paths:\n",
    "    label = tio.LabelMap(sample_path)\n",
    "    label.data[label.data==3] = 2\n",
    "    label.save(\"./temp/test.nii.gz\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34df73ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Test the output\n",
    "path = \"./temp/test.nii.gz\"\n",
    "label = tio.LabelMap(path)\n",
    "unique_labels = np.unique(label)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfd386",
   "metadata": {},
   "source": [
    "## Apply on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcd8e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in issue_file_paths:\n",
    "    name = path.split(\"/\")[-1]\n",
    "    label = tio.LabelMap(sample_path)\n",
    "    label.data[label.data==3] = 2\n",
    "    label.save(f\"./temp/train/{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd19d24",
   "metadata": {},
   "source": [
    "## Apply on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6dd1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_issue_file_paths = []\n",
    "\n",
    "for label_path in glob.glob(validation_labels_dir + '/*.nii.gz'):\n",
    "    split = label_path.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    \n",
    "    if split == '6':\n",
    "        validation_issue_file_paths.append(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bc83db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in validation_issue_file_paths:\n",
    "    name = path.split(\"/\")[-1]\n",
    "    label = tio.LabelMap(sample_path)\n",
    "    label.data[label.data==3] = 2\n",
    "    label.save(f\"./temp/val/{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347198a4",
   "metadata": {},
   "source": [
    "## Check Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e627b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "train_fixed = \"./temp/train\"\n",
    "for subject in glob.glob(train_fixed + \"/*.nii.gz\"):\n",
    "    label = tio.LabelMap(subject)\n",
    "    unique_labels = np.unique(label.data)\n",
    "    print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae900ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "validation_fixed = \"./temp/val\"\n",
    "for subject in glob.glob(validation_fixed + \"/*.nii.gz\"):\n",
    "    label = tio.LabelMap(subject)\n",
    "    unique_labels = np.unique(label.data)\n",
    "    print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f0d60",
   "metadata": {},
   "source": [
    "Patient 2 issue i.e. missing class might be related to `loss function`.\n",
    "Need to check it more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
