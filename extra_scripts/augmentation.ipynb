{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5014bd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData augmentation using TorchIO.\\nLink: https://torchio.readthedocs.io/index.html\\n\\nWe will upload each volume, apply transformation and save resulting volumes on the disk.\\nTransformations are applied to both volume and the mask.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data augmentation using TorchIO.\n",
    "Link: https://torchio.readthedocs.io/index.html\n",
    "\n",
    "We will upload each volume, apply transformation and save resulting volumes on the disk.\n",
    "Transformations are applied to both volume and the mask.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "659a09f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os, glob\n",
    "import torchio as tio\n",
    "from tqdm.notebook import tqdm, tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1df7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "# Since data size is huge, I am using external drive to save augmented data\n",
    "\n",
    "data_dir = os.path.abspath(\"/media/trojan/evo/3D-CT-Artery-Segmentation/data/train\")\n",
    "volumes_dir = os.path.join(data_dir + \"/volumes\")\n",
    "masks_dir = os.path.join(data_dir + \"/masks\")\n",
    "volumes_paths = sorted(glob.glob(volumes_dir + \"/\" + \"*.nii.gz\"))\n",
    "masks_paths = sorted(glob.glob(masks_dir + \"/\" + \"*.nii.gz\"))\n",
    "out_vol_dir = \"/media/trojan/evo/3D-CT-Artery-Segmentation/aug_data/volumes\"\n",
    "out_mask_dir = \"/media/trojan/evo/3D-CT-Artery-Segmentation/aug_data/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "017b6103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/1.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/10.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/11.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/12.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/13.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/14.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/15.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/16.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/17.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/2.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/3.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/4.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/6.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/7.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/8.nii.gz', '/media/trojan/evo/3D-CT-Artery-Segmentation/data/train/volumes/9.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(volumes_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78f6546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 16 subjects\n"
     ]
    }
   ],
   "source": [
    "# Load the volumes\n",
    "subjects = {}\n",
    "for (volume_path, mask_path) in zip(volumes_paths, masks_paths):\n",
    "    subject = tio.Subject(\n",
    "        vol=tio.ScalarImage(volume_path),\n",
    "        mask=tio.LabelMap(mask_path),\n",
    "    )\n",
    "    _id = volume_path.split('/')[-1].split('.')[0]\n",
    "    subjects[_id]=subject\n",
    "dataset = tio.SubjectsDataset(subjects.values())\n",
    "print('Dataset size:', len(dataset), 'subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59896c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference Link: https://torchio.readthedocs.io/transforms/augmentation.html#augmentation\n",
    "Check the link for more details.\n",
    "\"\"\"\n",
    "\n",
    "# Define transformations inside dicts\n",
    "transform_dict = {\n",
    "    tio.RandomBiasField(),\n",
    "    tio.RandomNoise(std=(0,100)),\n",
    "    tio.RandomFlip(axes=(0,1), flip_probability=1),\n",
    "    tio.RandomGhosting(),\n",
    "    tio.RandomSpike(),\n",
    "    tio.OneOf({\n",
    "        tio.RandomAffine(\n",
    "            scales=(0.9, 1.2),\n",
    "            degrees=(15, 15)\n",
    "        ): 0.8,\n",
    "        tio.RandomElasticDeformation(): 0.2,\n",
    "    }),\n",
    "} \n",
    "\n",
    "# Composed transformation to apply multiple transformations at once\n",
    "transform_compose = tio.Compose([\n",
    "    tio.RandomBiasField(p=0.2),\n",
    "    tio.RandomNoise(std=(0,100)),\n",
    "    tio.RandomFlip(p=0.2, axes=(0,1), flip_probability=1),\n",
    "    tio.RandomGhosting(p=0.2),\n",
    "    tio.RandomSpike(p=0.2),\n",
    "    tio.OneOf(p=0.2, transforms = {\n",
    "        tio.RandomAffine(\n",
    "            scales=(0.9, 1.2),\n",
    "            degrees=(15, 15)\n",
    "        ): 0.8,\n",
    "        tio.RandomElasticDeformation(): 0.2,\n",
    "    }),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96db7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final transform function\n",
    "# We will apply compose transformation with 20% probability\n",
    "# And single transformations with 80%\n",
    "\n",
    "# transform = tio.OneOf(transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d569073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af55e222b24f7392035f58f2ca7409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefd536427f74e56aa81f1d945309a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351ded63ffab41198a94ee27eaf6da2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad5e6ce81eb43728f5214a2e16b508b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b582047a474564bb84f0b7d4c7da92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7005b38d84d1995f838f835b52782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad6facdff55410fbc3f0623896f7d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "for transform in tqdm(transform_dict):\n",
    "    for idx, sample in tqdm(subjects.items()):\n",
    "        output = transform(sample)\n",
    "        temp = list(output.values())\n",
    "        temp[0].save(os.path.join(out_vol_dir, f\"{idx}_{i}.nii.gz\"))\n",
    "        temp[1].save(os.path.join(out_mask_dir, f\"{idx}_{i}.nii.gz\"))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "645dce71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7302ea1bd2d446fdb7ba57787aa8bfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83550b884d24e6baeb94f0a928125b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7912014658448f28443ed0f49dba75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, sample \u001b[38;5;129;01min\u001b[39;00m tqdm(subjects\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tnrange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      5\u001b[0m         temp[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_vol_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/transform.py:140\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    138\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/augmentation/composition.py:109\u001b[0m, in \u001b[0;36mOneOf.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m    107\u001b[0m transforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    108\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms[index]\n\u001b[0;32m--> 109\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/transform.py:140\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    138\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/augmentation/intensity/random_ghosting.py:91\u001b[0m, in \u001b[0;36mRandomGhosting.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m     89\u001b[0m     arguments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestore\u001b[39m\u001b[38;5;124m'\u001b[39m][name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore\n\u001b[1;32m     90\u001b[0m transform \u001b[38;5;241m=\u001b[39m Ghosting(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_include_exclude(arguments))\n\u001b[0;32m---> 91\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/transform.py:140\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    138\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/augmentation/intensity/random_ghosting.py:162\u001b[0m, in \u001b[0;36mGhosting.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m    160\u001b[0m transformed_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m image\u001b[38;5;241m.\u001b[39mdata:\n\u001b[0;32m--> 162\u001b[0m     transformed_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_ghosts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintensity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     transformed_tensors\u001b[38;5;241m.\u001b[39mappend(transformed_tensor)\n\u001b[1;32m    170\u001b[0m image\u001b[38;5;241m.\u001b[39mset_data(torch\u001b[38;5;241m.\u001b[39mstack(transformed_tensors))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/augmentation/intensity/random_ghosting.py:211\u001b[0m, in \u001b[0;36mGhosting.add_artifact\u001b[0;34m(self, tensor, num_ghosts, axis, intensity, restore_center)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    209\u001b[0m     spectrum[:, :, mk] \u001b[38;5;241m=\u001b[39m restore\n\u001b[0;32m--> 211\u001b[0m array_ghosts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv_fourier_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m array_ghosts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreal(array_ghosts)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mas_tensor(array_ghosts)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchio/transforms/fourier.py:15\u001b[0m, in \u001b[0;36mFourierTransform.inv_fourier_transform\u001b[0;34m(fshift)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minv_fourier_transform\u001b[39m(fshift: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     14\u001b[0m     f_ishift \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mifftshift(fshift)\n\u001b[0;32m---> 15\u001b[0m     img_back \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mifftn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_ishift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img_back\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mifftn\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:918\u001b[0m, in \u001b[0;36mifftn\u001b[0;34m(a, s, axes, norm)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_fftn_dispatcher)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mifftn\u001b[39m(a, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m    Compute the N-dimensional inverse discrete Fourier Transform.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_raw_fftnd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:707\u001b[0m, in \u001b[0;36m_raw_fftnd\u001b[0;34m(a, s, axes, function, norm)\u001b[0m\n\u001b[1;32m    705\u001b[0m itl\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m itl:\n\u001b[0;32m--> 707\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mifft\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:316\u001b[0m, in \u001b[0;36mifft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    314\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m    315\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_backward_norm(n, norm)\n\u001b[0;32m--> 316\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:73\u001b[0m, in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     a \u001b[38;5;241m=\u001b[39m swapaxes(a, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mpfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     r \u001b[38;5;241m=\u001b[39m swapaxes(r, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, sample in tqdm(subjects.items()):\n",
    "    for i in tnrange(1, 6):\n",
    "        output = transform(sample)\n",
    "        temp = list(output.values())\n",
    "        temp[0].save(os.path.join(out_vol_dir, f\"{idx}_{i}.nii.gz\"))\n",
    "        temp[1].save(os.path.join(out_mask_dir, f\"{idx}_{i}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c49353",
   "metadata": {},
   "source": [
    "While running the `augmentation` process, the file `5.nii.gz` gave an error because of size mismatch between `volume` and the `mask`.\n",
    "Not sure which volume is the correct one and was used for labeling originally. So excluding this file from training.\n",
    "\n",
    "Had to run it again on the remaining files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Delete after completion ###########################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b52d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "# Since data size is huge, I am using external drive to save augmented data\n",
    "\n",
    "data_dir = os.path.abspath(\"./data/train\")\n",
    "volumes_dir = os.path.join(data_dir + \"/volumes\")\n",
    "masks_dir = os.path.join(data_dir + \"/masks\")\n",
    "volumes_paths = sorted(glob.glob(volumes_dir + \"/\" + \"*.nii.gz\"))\n",
    "masks_paths = sorted(glob.glob(masks_dir + \"/\" + \"*.nii.gz\"))\n",
    "out_vol_dir = \"/run/user/1000/gvfs/afp-volume:host=SKIA.local,user=rajahaseeb147,volume=Shared/haseeb/3D-CT-Artery-Segmentation/aug_data/volumes\"\n",
    "out_mask_dir = \"/run/user/1000/gvfs/afp-volume:host=SKIA.local,user=rajahaseeb147,volume=Shared/haseeb/3D-CT-Artery-Segmentation/aug_data/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69f4196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/volumes/6.nii.gz', '/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/volumes/7.nii.gz', '/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/volumes/8.nii.gz', '/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/volumes/9.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(volumes_paths[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323375cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/masks/6.nii.gz', '/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/masks/7.nii.gz', '/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/masks/8.nii.gz', '/home/trojan/skia_projects/3D-CT-Artery-Segmentation/data/train/masks/9.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(masks_paths[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4505152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4 subjects\n"
     ]
    }
   ],
   "source": [
    "# Load the volumes\n",
    "subjects = {}\n",
    "for (volume_path, mask_path) in zip(volumes_paths[-4:], masks_paths[-4:]):\n",
    "    subject = tio.Subject(\n",
    "        vol=tio.ScalarImage(volume_path),\n",
    "        mask=tio.LabelMap(mask_path),\n",
    "    )\n",
    "    _id = volume_path.split('/')[-1].split('.')[0]\n",
    "    subjects[_id]=subject\n",
    "dataset = tio.SubjectsDataset(subjects.values())\n",
    "print('Dataset size:', len(dataset), 'subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc67ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference Link: https://torchio.readthedocs.io/transforms/augmentation.html#augmentation\n",
    "Check the link for more details.\n",
    "\"\"\"\n",
    "\n",
    "# Define transformations inside dicts\n",
    "transform_dict = {\n",
    "    #tio.Resample(4), # Don't use this\n",
    "    tio.RandomMotion(),\n",
    "    tio.RandomBiasField(),\n",
    "    tio.RandomNoise(std=(0,400)),\n",
    "    tio.RandomFlip(axes=(0,1), flip_probability=1),\n",
    "    tio.RandomAnisotropy(axes=(0,1,2), downsampling=6),\n",
    "    tio.RandomGhosting(),\n",
    "    tio.RandomSpike(),\n",
    "    tio.RandomBlur(std=(0,3)),\n",
    "    tio.RandomSwap(patch_size=30),\n",
    "    tio.RandomGamma(log_gamma=(-0.5, 0.5)),\n",
    "    tio.OneOf({\n",
    "        tio.RandomAffine(\n",
    "            scales=(0.9, 1.2),\n",
    "            degrees=(15, 15)\n",
    "        ): 0.8,\n",
    "        tio.RandomElasticDeformation(): 0.2,\n",
    "    }),\n",
    "} \n",
    "\n",
    "# Composed transformation to apply multiple transformations at once\n",
    "transform_compose = tio.Compose([\n",
    "    #tio.Resample(p=0.3, target=3),\n",
    "    tio.RandomMotion(p=0.2),\n",
    "    tio.RandomBiasField(p=0.3),\n",
    "    tio.RandomNoise(p=0.5, std=(0,400)),\n",
    "    tio.RandomFlip(axes=(0,1), flip_probability=0.5),\n",
    "    tio.RandomAnisotropy(p=0.3, axes=(0,1,2), downsampling=6),\n",
    "    tio.RandomGhosting(p=0.2),\n",
    "    tio.RandomSpike(p=0.3),\n",
    "    tio.RandomBlur(p=0.3, std=(0,3)),\n",
    "    tio.RandomSwap(p=0.2, patch_size=30),\n",
    "    tio.RandomGamma(p=0.3, log_gamma=(-0.5, 0.5)),\n",
    "    tio.OneOf(p=0.3, transforms = {\n",
    "        tio.RandomAffine(\n",
    "            scales=(0.9, 1.2),\n",
    "            degrees=(15, 15)\n",
    "        ): 0.8,\n",
    "        tio.RandomElasticDeformation(): 0.2,\n",
    "    }),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b557d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final transform function\n",
    "# We will apply compose transformation with 20% probability\n",
    "# And single transformations with 80%\n",
    "\n",
    "transform = tio.OneOf({transform_compose: 0.2, tio.OneOf(transform_dict): 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc87b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sample in subjects.items():\n",
    "    for i in range(1, 51):\n",
    "        output = transform(sample)\n",
    "        temp = list(output.values())\n",
    "        temp[0].save(os.path.join(out_vol_dir, f\"{idx}_{i}.nii.gz\"))\n",
    "        temp[1].save(os.path.join(out_mask_dir, f\"{idx}_{i}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f55d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c563134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
